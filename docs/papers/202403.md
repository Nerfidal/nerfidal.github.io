---
layout: default
title: March 2024
parent: Papers
nav_order: 202403
---

<!---metadata--->


## NeRF-VPT: Learning Novel View Representations with Neural Radiance  Fields via View Prompt Tuning

nerf
{: .label .label-blue }

| Published | Authors | Category | |
|:---:|:---:|:---:|:---:|
| 2024-03-02 | Linsheng Chen, Guangrun Wang, Liuchun Yuan, Keze Wang, Ken Deng, Philip H. S. Torr | cs.CV | [PDF](http://arxiv.org/pdf/2403.01325v1){: .btn .btn-green } |

**Abstract**: Neural Radiance Fields (NeRF) have garnered remarkable success in novel view
synthesis. Nonetheless, the task of generating high-quality images for novel
views persists as a critical challenge. While the existing efforts have
exhibited commendable progress, capturing intricate details, enhancing
textures, and achieving superior Peak Signal-to-Noise Ratio (PSNR) metrics
warrant further focused attention and advancement. In this work, we propose
NeRF-VPT, an innovative method for novel view synthesis to address these
challenges. Our proposed NeRF-VPT employs a cascading view prompt tuning
paradigm, wherein RGB information gained from preceding rendering outcomes
serves as instructive visual prompts for subsequent rendering stages, with the
aspiration that the prior knowledge embedded in the prompts can facilitate the
gradual enhancement of rendered image quality. NeRF-VPT only requires sampling
RGB data from previous stage renderings as priors at each training stage,
without relying on extra guidance or complex techniques. Thus, our NeRF-VPT is
plug-and-play and can be readily integrated into existing methods. By
conducting comparative analyses of our NeRF-VPT against several NeRF-based
approaches on demanding real-scene benchmarks, such as Realistic Synthetic 360,
Real Forward-Facing, Replica dataset, and a user-captured dataset, we
substantiate that our NeRF-VPT significantly elevates baseline performance and
proficiently generates more high-quality novel view images than all the
compared state-of-the-art methods. Furthermore, the cascading learning of
NeRF-VPT introduces adaptability to scenarios with sparse inputs, resulting in
a significant enhancement of accuracy for sparse-view novel view synthesis. The
source code and dataset are available at
\url{https://github.com/Freedomcls/NeRF-VPT}.

Comments:
- AAAI 2024

---

## Neural radiance fields-based holography [Invited]

nerf
{: .label .label-blue }

| Published | Authors | Category | |
|:---:|:---:|:---:|:---:|
| 2024-03-02 | Minsung Kang, Fan Wang, Kai Kumano, Tomoyoshi Ito, Tomoyoshi Shimobaba | cs.CV | [PDF](http://arxiv.org/pdf/2403.01137v1){: .btn .btn-green } |

**Abstract**: This study presents a novel approach for generating holograms based on the
neural radiance fields (NeRF) technique. Generating three-dimensional (3D) data
is difficult in hologram computation. NeRF is a state-of-the-art technique for
3D light-field reconstruction from 2D images based on volume rendering. The
NeRF can rapidly predict new-view images that do not include a training
dataset. In this study, we constructed a rendering pipeline directly from a 3D
light field generated from 2D images by NeRF for hologram generation using deep
neural networks within a reasonable time. The pipeline comprises three main
components: the NeRF, a depth predictor, and a hologram generator, all
constructed using deep neural networks. The pipeline does not include any
physical calculations. The predicted holograms of a 3D scene viewed from any
direction were computed using the proposed pipeline. The simulation and
experimental results are presented.



---

## Neural Field Classifiers via Target Encoding and Classification Loss

nerf
{: .label .label-blue }

| Published | Authors | Category | |
|:---:|:---:|:---:|:---:|
| 2024-03-02 | Xindi Yang, Zeke Xie, Xiong Zhou, Boyu Liu, Buhua Liu, Yi Liu, Haoran Wang, Yunfeng Cai, Mingming Sun | cs.CV | [PDF](http://arxiv.org/pdf/2403.01058v1){: .btn .btn-green } |

**Abstract**: Neural field methods have seen great progress in various long-standing tasks
in computer vision and computer graphics, including novel view synthesis and
geometry reconstruction. As existing neural field methods try to predict some
coordinate-based continuous target values, such as RGB for Neural Radiance
Field (NeRF), all of these methods are regression models and are optimized by
some regression loss. However, are regression models really better than
classification models for neural field methods? In this work, we try to visit
this very fundamental but overlooked question for neural fields from a machine
learning perspective. We successfully propose a novel Neural Field Classifier
(NFC) framework which formulates existing neural field methods as
classification tasks rather than regression tasks. The proposed NFC can easily
transform arbitrary Neural Field Regressor (NFR) into its classification
variant via employing a novel Target Encoding module and optimizing a
classification loss. By encoding a continuous regression target into a
high-dimensional discrete encoding, we naturally formulate a multi-label
classification task. Extensive experiments demonstrate the impressive
effectiveness of NFC at the nearly free extra computational costs. Moreover,
NFC also shows robustness to sparse inputs, corrupted images, and dynamic
scenes.

Comments:
- ICLR 2024 Main Conference; 17 pages; 11 figures; 13 tables

---

## DISORF: A Distributed Online NeRF Training and Rendering Framework for  Mobile Robots

nerf
{: .label .label-blue }

| Published | Authors | Category | |
|:---:|:---:|:---:|:---:|
| 2024-03-01 | Chunlin Li, Ruofan Liang, Hanrui Fan, Zhengen Zhang, Sankeerth Durvasula, Nandita Vijaykumar | cs.RO | [PDF](http://arxiv.org/pdf/2403.00228v1){: .btn .btn-green } |

**Abstract**: We present a framework, DISORF, to enable online 3D reconstruction and
visualization of scenes captured by resource-constrained mobile robots and edge
devices. To address the limited compute capabilities of edge devices and
potentially limited network availability, we design a framework that
efficiently distributes computation between the edge device and remote server.
We leverage on-device SLAM systems to generate posed keyframes and transmit
them to remote servers that can perform high quality 3D reconstruction and
visualization at runtime by leveraging NeRF models. We identify a key challenge
with online NeRF training where naive image sampling strategies can lead to
significant degradation in rendering quality. We propose a novel shifted
exponential frame sampling method that addresses this challenge for online NeRF
training. We demonstrate the effectiveness of our framework in enabling
high-quality real-time reconstruction and visualization of unknown scenes as
they are captured and streamed from cameras in mobile robots and edge devices.


