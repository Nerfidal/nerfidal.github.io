---
layout: default
title: August
parent: 2020
nav_order: 8
---
<!---metadata--->

## NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo  Collections

nerf
{: .label .label-blue }

| Published | Authors | Category | |
|:---:|:---:|:---:|:---:|
| 2020-08-05 | Ricardo Martin-Brualla, Noha Radwan, Mehdi S. M. Sajjadi, Jonathan T. Barron, Alexey Dosovitskiy, Daniel Duckworth | cs.CV | [PDF](http://arxiv.org/pdf/2008.02268v3){: .btn .btn-green } |

**Abstract**: We present a learning-based method for synthesizing novel views of complex
scenes using only unstructured collections of in-the-wild photographs. We build
on Neural Radiance Fields (NeRF), which uses the weights of a multilayer
perceptron to model the density and color of a scene as a function of 3D
coordinates. While NeRF works well on images of static subjects captured under
controlled settings, it is incapable of modeling many ubiquitous, real-world
phenomena in uncontrolled images, such as variable illumination or transient
occluders. We introduce a series of extensions to NeRF to address these issues,
thereby enabling accurate reconstructions from unstructured image collections
taken from the internet. We apply our system, dubbed NeRF-W, to internet photo
collections of famous landmarks, and demonstrate temporally consistent novel
view renderings that are significantly closer to photorealism than the prior
state of the art.

Comments:
- Project website: https://nerf-w.github.io. Ricardo Martin-Brualla,
  Noha Radwan, and Mehdi S. M. Sajjadi contributed equally to this work.
  Updated with results for three additional scenes